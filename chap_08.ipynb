{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('optAlgos': conda)"
  },
  "interpreter": {
   "hash": "ba3b919a19380c03e01f18adb9941583c39169f4907f8bc2002c90bf52d7e13c"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Chapter 8: Stochastic Methods"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import copy\n",
    "import jax\n",
    "import numpy as np\n",
    "from scipy import stats"
   ]
  },
  {
   "source": [
    "## Algorithm 8.1"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoisyDescent:\n",
    "\n",
    "    def __init__(self, submethod, sigma):\n",
    "        self.submethod = submethod\n",
    "        self.sigma = sigma\n",
    "        self.k = 1\n",
    "    \n",
    "    def step(self, f, gradient, x):\n",
    "        x = self.submethod.step(f, gradient, x)\n",
    "        sigma = self.sigma[self.k]\n",
    "        x += sigma*np.random.randn(x.shape[0])\n",
    "        self.k += 1\n",
    "\n",
    "        return x"
   ]
  },
  {
   "source": [
    "### Example"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[  1.3609072 -12.642112  -12.549556 ]\n"
     ]
    }
   ],
   "source": [
    "class GradientDescent:\n",
    "    def __init__(self, alpha):\n",
    "        self.alpha = alpha # Î±\n",
    "\n",
    "    def step(self, f, gradient, x):\n",
    "        g = gradient(x)\n",
    "        return x - self.alpha*g\n",
    "\n",
    "def fun(x):\n",
    "    return jax.numpy.sin(x[0]*x[1])+jax.numpy.exp(x[1]+x[2])-x[2]\n",
    "\n",
    "x_0 = np.array([1.0, 2.0, 3.0])\n",
    "gradient = jax.grad(fun)\n",
    "submethod = GradientDescent(0.1)\n",
    "sigma = [1.1/k for k in range(1,21)]\n",
    "M = NoisyDescent(submethod, sigma)\n",
    "x_1 = M.step(fun, gradient, x_0) \n",
    "print(x_1)"
   ]
  },
  {
   "source": [
    "## Algorithm 8.2"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_positive_spanning_set(alpha, n):\n",
    "    delta = np.round(1/np.sqrt(alpha))\n",
    "    L = np.diag(delta*np.random.choice([-1,1],size=n ))\n",
    "    for i in range(0,n-1):\n",
    "        for j in range(i+1,n):\n",
    "            L[j,i] = np.random.uniform(-delta+1,delta-1)\n",
    "    D = L[np.random.permutation(n),:]\n",
    "    D = D[:, np.random.permutation(n)]\n",
    "    D = np.concatenate([D, -np.sum(D,axis=1).reshape(-1,1)], axis=1)\n",
    "    return [D[:,i] for i in range(0, n+1)]"
   ]
  },
  {
   "source": [
    "## Algorithm 8.3"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mesh_adaptive_direct_search(f, x, epsilon):\n",
    "    alpha, y, n = 1, f(x), x.shape[0]\n",
    "    while alpha > epsilon:\n",
    "        improved = False\n",
    "        for i, d in enumerate(rand_positive_spanning_set(alpha, n)):\n",
    "            x_prime = x + alpha*d\n",
    "            y_prime = f(x_prime)\n",
    "            if y_prime < y:\n",
    "                x, y, improved = x_prime, y_prime, True\n",
    "                x_prime = x + 3*alpha*d\n",
    "                y_prime = f(x_prime)\n",
    "                if y_prime < y:\n",
    "                    x, y = x_prime, y_prime\n",
    "        alpha = np.min([4*alpha,1]) if improved else alpha/4\n",
    "    return x"
   ]
  },
  {
   "source": [
    "### Example"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0.98191814 1.61222439]\n"
     ]
    }
   ],
   "source": [
    "def fun(x):\n",
    "    return -np.exp(-(x[0]*x[1] - 1.5)**2 -(x[1]-1.5)**2)\n",
    "x_0 = np.array([2.75, 2.25])\n",
    "epsilon = 0.01\n",
    "x_sol = mesh_adaptive_direct_search(fun, x_0, epsilon)\n",
    "print(x_sol)"
   ]
  },
  {
   "source": [
    "## Algorithm 8.4"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulated_annealing(f, x, T, t, k_max):\n",
    "    y = f(x)\n",
    "    x_best, y_best = x, y\n",
    "    for k in range(k_max):\n",
    "        x_prime = x + T.rvs()\n",
    "        y_prime = f(x_prime)\n",
    "        delta_y = y_prime - y\n",
    "        if delta_y <= 0 or np.random.random() < np.exp(-delta_y/t(k)):\n",
    "            x, y = x_prime, y_prime\n",
    "        \n",
    "        if y_prime < y_best:\n",
    "            x_best, y_best = x_prime, y_prime\n",
    "        \n",
    "    \n",
    "    return x_best"
   ]
  },
  {
   "source": [
    "### Example"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[1.56344716 1.06344716]\n"
     ]
    }
   ],
   "source": [
    "def fun(x):\n",
    "    return -np.exp(-(x[0]*x[1] - 1.5)**2 -(x[1]-1.5)**2)\n",
    "x_0 = np.array([2.75, 2.25])\n",
    "k_max = 2000\n",
    "t = lambda k : 500.0/(k+1)\n",
    "T = stats.norm()\n",
    "x_sol = simulated_annealing(fun, x_0, T, t, k_max)\n",
    "print(x_sol)"
   ]
  },
  {
   "source": [
    "## Algorithm 8.5"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corona_update(v, a, c, ns):\n",
    "    for i in range(v.shape[0]):\n",
    "        ai, ci = a[i], c[i]\n",
    "        if ai > 0.6*ns:\n",
    "            v[i] *= (1 + ci*(ai/ns - 0.6)/0.4)\n",
    "        elif ai < 0.4*ns:\n",
    "            v[i] /= (1 + ci*(0.4-ai/ns)/0.4)\n",
    "\n",
    "    return v"
   ]
  },
  {
   "source": [
    "## Algorithm 8.6"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adaptive_simulated_annealing(f, x, v, t, epsilon, ns=20, nepsilon=4, gamma =0.85):\n",
    "    nt = np.max([100, 5*x.shape[0]])\n",
    "    c = np.zeros(x.shape[0])\n",
    "    c.fill(2)\n",
    "    y = f(x)\n",
    "    x_best, y_best = x, y\n",
    "    y_arr, n, U = [], x.shape[0], stats.uniform(-1,2)\n",
    "    a, counts_cycles, counts_resets = np.zeros(n), 0, 0\n",
    "\n",
    "    while True:\n",
    "        for i in range(n):\n",
    "            print(np.array(basis(i,n))*U.rvs()*v[i])\n",
    "            x_prime = x + np.array(basis(i,n))*U.rvs()*v[i]\n",
    "            y_prime = f(x_prime)\n",
    "            delta_y = y_prime - y\n",
    "            if delta_y < 0 or np.random.random() < np.exp(-delta_y/t):\n",
    "                x, y = x_prime, y_prime\n",
    "                a[i] += 1\n",
    "                if y_prime < y_best:\n",
    "                    x_best, y_best = x_prime, y_prime\n",
    "            \n",
    "        counts_cycles += 1\n",
    "        if counts_cycles >= ns:\n",
    "            counts_cycles = 0\n",
    "            v = corona_update(v, a, c, ns)\n",
    "            a.fill(0)\n",
    "            counts_resets += 1\n",
    "\n",
    "            if counts_resets >= nt:\n",
    "                t *= gamma\n",
    "                counts_resets = 0\n",
    "                y_arr.insert(0,y)\n",
    "\n",
    "                if not ( (len(y_arr) > nepsilon) and (y_arr[-1] - y_best <= epsilon) and np.all( [ np.abs(y_arr[-1]-y_arr[-1-u]) <= epsilon for u in range(nepsilon)]) ):\n",
    "                    x, y = x_best, y_best\n",
    "                else:\n",
    "                    break\n",
    "    return x_best"
   ]
  },
  {
   "source": [
    "## Algorithm 8.7"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_method(f, P, k_max, m=100, m_elite=10):\n",
    "    for k in range(k_max):\n",
    "        samples = P.rvs(m)\n",
    "        order = np.argsort([f(samples[i]) for i in range(m)])\n",
    "        P.fit(samples[order[:m_elite]]) #Currently scipy does not support a \"fit\" function for multivariate distributions\n",
    "    return P"
   ]
  }
 ]
}
{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('optAlgos': conda)"
  },
  "interpreter": {
   "hash": "ba3b919a19380c03e01f18adb9941583c39169f4907f8bc2002c90bf52d7e13c"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Chapter 8: Stochastic Methods"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "from copy import copy\n",
    "import jax\n",
    "import numpy as np\n",
    "from scipy import stats"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Algorithm 8.1"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class NoisyDescent:\n",
    "\n",
    "    def __init__(self, submethod, sigma):\n",
    "        self.submethod = submethod\n",
    "        self.sigma = sigma\n",
    "        self.k = 1\n",
    "    \n",
    "    def step(self, f, gradient, x):\n",
    "        x = self.submethod.step(f, gradient, x)\n",
    "        sigma = self.sigma[self.k]\n",
    "        x += sigma*np.random.randn(x.shape[0])\n",
    "        self.k += 1\n",
    "\n",
    "        return x"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Example"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "class GradientDescent:\n",
    "    def __init__(self, alpha):\n",
    "        self.alpha = alpha # α\n",
    "\n",
    "    def step(self, f, gradient, x):\n",
    "        g = gradient(x)\n",
    "        return x - self.alpha*g\n",
    "\n",
    "def fun(x):\n",
    "    return jax.numpy.sin(x[0]*x[1])+jax.numpy.exp(x[1]+x[2])-x[2]\n",
    "\n",
    "x_0 = np.array([1.0, 2.0, 3.0])\n",
    "gradient = jax.grad(fun)\n",
    "submethod = GradientDescent(0.1)\n",
    "sigma = [1.1/k for k in range(1,21)]\n",
    "M = NoisyDescent(submethod, sigma)\n",
    "x_1 = M.step(fun, gradient, x_0) \n",
    "print(x_1)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[  1.3609072 -12.642112  -12.549556 ]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Algorithm 8.2"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "def rand_positive_spanning_set(alpha, n):\n",
    "    delta = np.round(1/np.sqrt(alpha))\n",
    "    L = np.diag(delta*np.random.choice([-1,1],size=n ))\n",
    "    for i in range(0,n-1):\n",
    "        for j in range(i+1,n):\n",
    "            L[j,i] = np.random.uniform(-delta+1,delta-1)\n",
    "    D = L[np.random.permutation(n),:]\n",
    "    D = D[:, np.random.permutation(n)]\n",
    "    D = np.concatenate([D, -np.sum(D,axis=1).reshape(-1,1)], axis=1)\n",
    "    return [D[:,i] for i in range(0, n+1)]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Algorithm 8.3"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "def mesh_adaptive_direct_search(f, x, epsilon):\n",
    "    alpha, y, n = 1, f(x), x.shape[0]\n",
    "    while alpha > epsilon:\n",
    "        improved = False\n",
    "        for i, d in enumerate(rand_positive_spanning_set(alpha, n)):\n",
    "            x_prime = x + alpha*d\n",
    "            y_prime = f(x_prime)\n",
    "            if y_prime < y:\n",
    "                x, y, improved = x_prime, y_prime, True\n",
    "                x_prime = x + 3*alpha*d\n",
    "                y_prime = f(x_prime)\n",
    "                if y_prime < y:\n",
    "                    x, y = x_prime, y_prime\n",
    "        alpha = np.min([4*alpha,1]) if improved else alpha/4\n",
    "    return x"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Example"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "def fun(x):\n",
    "    return -np.exp(-(x[0]*x[1] - 1.5)**2 -(x[1]-1.5)**2)\n",
    "x_0 = np.array([2.75, 2.25])\n",
    "epsilon = 0.01\n",
    "x_sol = mesh_adaptive_direct_search(fun, x_0, epsilon)\n",
    "print(x_sol)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0.98191814 1.61222439]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Algorithm 8.4"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "def simulated_annealing(f, x, T, t, k_max):\n",
    "    y = f(x)\n",
    "    x_best, y_best = x, y\n",
    "    for k in range(k_max):\n",
    "        x_prime = x + T.rvs()\n",
    "        y_prime = f(x_prime)\n",
    "        delta_y = y_prime - y\n",
    "        if delta_y <= 0 or np.random.random() < np.exp(-delta_y/t(k)):\n",
    "            x, y = x_prime, y_prime\n",
    "        \n",
    "        if y_prime < y_best:\n",
    "            x_best, y_best = x_prime, y_prime\n",
    "        \n",
    "    \n",
    "    return x_best"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Example"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "def fun(x):\n",
    "    return -np.exp(-(x[0]*x[1] - 1.5)**2 -(x[1]-1.5)**2)\n",
    "x_0 = np.array([2.75, 2.25])\n",
    "k_max = 2000\n",
    "t = lambda k : 500.0/(k+1)\n",
    "T = stats.norm()\n",
    "x_sol = simulated_annealing(fun, x_0, T, t, k_max)\n",
    "print(x_sol)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[1.56344716 1.06344716]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Algorithm 8.5"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "def corona_update(v, a, c, ns):\n",
    "    for i in range(v.shape[0]):\n",
    "        ai, ci = a[i], c[i]\n",
    "        if ai > 0.6*ns:\n",
    "            v[i] *= (1 + ci*(ai/ns - 0.6)/0.4)\n",
    "        elif ai < 0.4*ns:\n",
    "            v[i] /= (1 + ci*(0.4-ai/ns)/0.4)\n",
    "\n",
    "    return v"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Algorithm 8.6"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "source": [
    "def adaptive_simulated_annealing(f, x, v, t, epsilon, ns=20, nepsilon=4, gamma =0.85):\n",
    "    nt = np.max([100, 5*x.shape[0]])\n",
    "    c = np.zeros(x.shape[0])\n",
    "    c.fill(2)\n",
    "    y = f(x)\n",
    "    x_best, y_best = x, y\n",
    "    y_arr, n, U = [], x.shape[0], stats.uniform(-1,2)\n",
    "    a, counts_cycles, counts_resets = np.zeros(n), 0, 0\n",
    "\n",
    "    while True:\n",
    "        for i in range(n):\n",
    "            print(np.array(basis(i,n))*U.rvs()*v[i])\n",
    "            x_prime = x + np.array(basis(i,n))*U.rvs()*v[i]\n",
    "            y_prime = f(x_prime)\n",
    "            delta_y = y_prime - y\n",
    "            if delta_y < 0 or np.random.random() < np.exp(-delta_y/t):\n",
    "                x, y = x_prime, y_prime\n",
    "                a[i] += 1\n",
    "                if y_prime < y_best:\n",
    "                    x_best, y_best = x_prime, y_prime\n",
    "            \n",
    "        counts_cycles += 1\n",
    "        if counts_cycles >= ns:\n",
    "            counts_cycles = 0\n",
    "            v = corona_update(v, a, c, ns)\n",
    "            a.fill(0)\n",
    "            counts_resets += 1\n",
    "\n",
    "            if counts_resets >= nt:\n",
    "                t *= gamma\n",
    "                counts_resets = 0\n",
    "                y_arr.insert(0,y)\n",
    "\n",
    "                if not ( (len(y_arr) > nepsilon) and (y_arr[-1] - y_best <= epsilon) and np.all( [ np.abs(y_arr[-1]-y_arr[-1-u]) <= epsilon for u in range(nepsilon)]) ):\n",
    "                    x, y = x_best, y_best\n",
    "                else:\n",
    "                    break\n",
    "    return x_best"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Algorithm 8.7"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "def cross_entropy_method(f, P, k_max, m=100, m_elite=10):\n",
    "    '''\n",
    "    The Julia code prototype as is can not be implemented in Python\n",
    "    '''\n",
    "    for k in range(k_max):\n",
    "        samples = P.rvs(m)\n",
    "        order = np.argsort([f(samples[i]) for i in range(m)])\n",
    "        P.fit(samples[order[:m_elite]]) #Currently scipy does not support the \"fit\" function for multivariate distributions\n",
    "    return P"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Algorithm 8.8"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def natural_evolution_strategies(f, theta, k_max, m =100, alpha=0.01):\n",
    "    '''\n",
    "    The Julia code prototype as is can not be implemented in Python\n",
    "    '''\n",
    "    for k in range(k_max):\n",
    "        samples = [theta.rvs() for i in range(m)]\n",
    "        theta = update(theta, samples, m, alpha) #Needs to know the log likehood function of the distribution 'theta'\n",
    "    return theta"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Algorithm 8.9"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "source": [
    "def covariance_matrix_adaptatiton(f, x, k_max, sigma=1.0, m=None, m_elite=None):\n",
    "    '''\n",
    "    Problems with computing Σ^-0.5\n",
    "    '''\n",
    "    if m == None:\n",
    "        m = 4 + int(np.floor(3*np.log(x.shape[0])))\n",
    "    \n",
    "    if m_elite == None:\n",
    "        m_elite = int(np.divide(m,2))\n",
    "\n",
    "    mu, n = copy(x), x.shape[0]\n",
    "    ws = np.repeat(np.log((m+1)/2),m) - np.log(np.arange(1,m+1,1) )\n",
    "    ws[:m_elite] /= np.sum(ws[:m_elite])\n",
    "    mu_eff = 1 / np.sum(ws[:m_elite]**2)\n",
    "    csigma = (mu_eff + 2)/(n + mu_eff + 5)\n",
    "    dsigma = 1 + 2*np.max([0, np.sqrt((mu_eff-1)/(n+1))-1]) + csigma\n",
    "    cSigma = ( 4 + mu_eff/n ) / ( n + 4 + 2*mu_eff/n)\n",
    "    c1 = 2 / ((n+1.3)*2 + mu_eff)\n",
    "    cmu = np.min([1- c1, 2*(mu_eff-2+1/mu_eff)/((n+2)**2 + mu_eff) ])\n",
    "    ws[m_elite:] *= - (1+c1/cmu)/np.sum(ws[m_elite:])\n",
    "    E = n**0.5*(1-1/(4*n)+1/(21*n**2))\n",
    "    psigma, pSigma, Sigma = np.zeros(n), np.zeros(n), np.identity(n)\n",
    "\n",
    "    for k in range(k_max):\n",
    "\n",
    "        P = stats.multivariate_normal(mean=mu, cov=sigma**2*Sigma)\n",
    "        xs = [ P.rvs() for i in range(m) ]\n",
    "        ys = [ f(x) for x in xs ]\n",
    "        is_ = np.argsort(ys)\n",
    "\n",
    "        deltas = [ (x-mu)/sigma for x in xs ]\n",
    "        deltaw = np.sum( [ ws[i]*deltas[is_[i]] for i in range(m_elite) ]) \n",
    "        mu += sigma*deltaw\n",
    "        C = Sigma**(-0.5)\n",
    "        mask = np.ma.masked_equal(C, np.infty)\n",
    "        C = mask.filled(fill_value=0)\n",
    "\n",
    "        psigma = (1-csigma)*psigma + np.sqrt(csigma*(2-csigma)*mu_eff)*np.dot(C,np.repeat(deltaw,n,axis=0))\n",
    "        sigma *= np.exp(csigma/dsigma * ( np.linalg.norm(psigma)/E-1) )\n",
    "        hsigma = np.array([ int(np.linalg.norm(psigma[i])/np.sqrt(1-(1-csigma)**(2*k)) < (1.4+2/(n+1))*E) for i in range(n)])\n",
    "        pSigma = (1 - cSigma)*pSigma + hsigma*np.sqrt(cSigma*(2-cSigma)*mu_eff)*deltaw\n",
    "\n",
    "        w0 = [ ws[i] if ws[i] >= 0 else n*ws[i]/np.linalg.norm(C*deltas[is_[i]])**2 for i in range(m) ]\n",
    "        Sigma = (1 - c1 - cmu)*Sigma + \\\n",
    "                c1*(np.dot(pSigma,pSigma) + (1-hsigma) * cSigma*(2-cSigma) * cSigma ) + \\\n",
    "                cmu*np.sum( [w0[i]*np.dot(deltas[is_[i]],deltas[is_[i]])  for i in range(m)] )\n",
    "        \n",
    "        Sigma = np.triu(Sigma) + np.triu(Sigma,1).T\n",
    "\n",
    "    return mu"
   ],
   "outputs": [],
   "metadata": {}
  }
 ]
}
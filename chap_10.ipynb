{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Chapter 10: Constraints"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np\n",
    "import jax"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Algorithm 10.1"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "def penalty_method(f, p, x, min_f, k_max, rho=1, gamma=2):\n",
    "    for k in range(k_max):\n",
    "        x = min_f(lambda x_p: f(x_p) + rho*p(x_p), x)\n",
    "        rho *= gamma\n",
    "        if p(x) == 0:\n",
    "            return x\n",
    "\n",
    "    return x"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Example"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "def backtracking_line_search(f, gradient, x, d, alpha, p=0.5, beta=1e-4):\n",
    "    y, g = f(x), gradient\n",
    "    while f(x+alpha*d) > y + beta*alpha*(np.dot(g(x),d)):\n",
    "        alpha *= p\n",
    "    return alpha\n",
    "\n",
    "def aproximate_line_search(f, x):\n",
    "    '''\n",
    "    One Step of Aproximate Line Search with Backtracking\n",
    "    '''\n",
    "    gradient = jax.grad(f)\n",
    "    d = -gradient(x)\n",
    "\n",
    "    alpha = backtracking_line_search(f, gradient, x, d, 1.0)\n",
    "\n",
    "    return x + alpha*d\n",
    "\n",
    "def f(x):\n",
    "    return jax.numpy.sin(x[0]*x[1])+jax.numpy.exp(x[1]+x[2])-x[2]\n",
    "\n",
    "p = lambda x: (x[0] + x[1] + x[2])**2\n",
    "x = np.array([1.0, 2.0, 3.0])\n",
    "k_max = 10\n",
    "x_sol = penalty_method(f, p, x, aproximate_line_search, k_max)\n",
    "print(x_sol)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[ 1.7996317  -1.419845   -0.37155974]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Algorithm 10.2"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def augmented_lagrange_method(f, h, x, min_f, k_max, rho=1, gamma=2):\n",
    "    \n",
    "    lambda_ = np.zeros(len(h(x)))\n",
    "\n",
    "    for k in range(k_max):\n",
    "        p = lambda x: f(x) + rho/2*np.sum(h(x)**2) - np.dot(lambda_, h(x))\n",
    "        x =  min_f(lambda x_p: f(x_p) + p(x_p), x)\n",
    "        rho *= gamma\n",
    "        lambda_ -= rho*h(x)\n",
    "\n",
    "    return x"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Algorithm 10.3"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def interior_point_method(f, p, x, min_f, rho=1, gamma=2, epsilon = 0.001):\n",
    "    delta = np.infty\n",
    "\n",
    "    while delta > epsilon:\n",
    "        x_prime = min_f(lambda x_p: f(x_p) + p(x_p)/rho, x)\n",
    "        delta = (np.sum(x_prime - x)**2)**0.5\n",
    "        x = x_prime\n",
    "        rho *= gamma\n",
    "    \n",
    "    return x"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('optAlgos': conda)"
  },
  "interpreter": {
   "hash": "ba3b919a19380c03e01f18adb9941583c39169f4907f8bc2002c90bf52d7e13c"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}